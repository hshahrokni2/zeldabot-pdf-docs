# Comment: Please note - After compaction, twin agents are FULLY FUNCTIONAL
# Both Qwen (Ollama) and Gemini (Vertex AI) working with HTTP 200 success
# Use europe-west4 region for Vertex AI, requires service account credentials
# Performance: Qwen 4-9s, Gemini 7.1s multimodal, both reliable for production

# Qwen 2.5 VL Instruct API Configuration (H100 server via Ollama)
QWEN_VL_API_URL=http://localhost:11434/v1/chat/completions

# Sectionizer Configuration  
SECTIONIZER_MODE=heuristic
DOC_CONCURRENCY=4
ORCH_DPI=200

# PostgreSQL Database Configuration (H100 server - 200 training PDFs ready)
PGHOST=localhost
PGPORT=5432
PGDATABASE=zelda
PGUSER=zelda
PGPASSWORD=Zelda4Ever!
PGSSLMODE=prefer

# Gemini API Configuration (Vertex AI recommended for production)
GEMINI_API_KEY=AIzaSyD0y92BjcnvUgRlWsA1oPSIWV5QaJcCrNw
GEMINI_MODEL=gemini-2.5-pro
GEMINI_STRICT_SINGLE_PAGE=1

# Comment: For Vertex AI setup, also configure:
# GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"
# GEMINI_ENDPOINT="https://europe-west4-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/europe-west4/publishers/google/models/gemini-2.5-pro:generateContent"